{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "data_iris = pd.read_csv('iris.csv')\n",
    "X_iris = data_iris.iloc[:, 1:-1]\n",
    "s = data_iris.iloc[:, -1]\n",
    "y_iris=[]\n",
    "for i in range(0,len(s)):\n",
    "    if s[i]=='Iris-setosa':\n",
    "        y_iris.append(0)\n",
    "    if s[i]=='Iris-versicolor':\n",
    "        y_iris.append(1)\n",
    "    if s[i]=='Iris-virginica':\n",
    "        y_iris.append(2)\n",
    "\n",
    "\n",
    "y_iris = DataFrame (y_iris)\n",
    "y_iris.columns = ['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information after train-test split:\n",
      "The train-set includes 120 instances and 120 corresponding categories\n",
      "\n",
      "The test-set includes 30 instances and 30 corresponding categories\n",
      "\n",
      "First few rows of unified train-set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  target\n",
       "22            4.6           3.6            1.0           0.2       0\n",
       "15            5.7           4.4            1.5           0.4       0\n",
       "65            6.7           3.1            4.4           1.4       1\n",
       "11            4.8           3.4            1.6           0.2       0\n",
       "42            4.4           3.2            1.3           0.2       0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "### The Following section splits the iris dataset directly from sklean\n",
    "# --------------------------------------------------------\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# display train-test split information\n",
    "# --------------------------------------------------------\n",
    "print ('Information after train-test split:')\n",
    "print('The train-set includes %d instances and %d corresponding categories\\n' %(X_train.shape[0],y_train.shape[0]))\n",
    "print('The test-set includes %d instances and %d corresponding categories\\n' %(X_test.shape[0],y_test.shape[0]))\n",
    "\n",
    "# --------------------------------------------------------\n",
    "## concatinate the X_train and y_train for Naive Bayes training:\n",
    "# --------------------------------------------------------\n",
    "train_set = pd.concat((X_train, y_train), axis=1)\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "# Display the first few rows of the training-set:\n",
    "# --------------------------------------------------------\n",
    "print('First few rows of unified train-set:')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCategoryPriors(trainingSet):\n",
    "    \n",
    "    yTrain = trainingSet[['target']]\n",
    "    total=yTrain.shape[0]\n",
    "    uniqueClasses = np.unique(yTrain['target'].values)\n",
    "    helpLi=[]\n",
    "    li=[]\n",
    "    for m in uniqueClasses:\n",
    "        helpLi.append(0)\n",
    "        li.append(0)\n",
    "    \n",
    "    for i in yTrain['target']:\n",
    "        for x in uniqueClasses:\n",
    "            if i==uniqueClasses[x]:\n",
    "                helpLi[x]+=1\n",
    "    for x in range(len(li)):\n",
    "        li[x]=helpLi[x]/total\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for expected class prior ...\n",
      "... 'calcCategoryPriors' test passed successfully :-)\n",
      "prior for category 0: 0.333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arrPriors = calcCategoryPriors(train_set)\n",
    "priorClass_0 = arrPriors[0]\n",
    "print ('testing for expected class prior ...')\n",
    "assert int(priorClass_0*100)==33,'wrong prior for class-0'\n",
    "print (\"... 'calcCategoryPriors' test passed successfully :-)\")\n",
    "print ('prior for category 0: %f' %(priorClass_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMeanLikelihood(trainingSet):\n",
    "    yTrain = trainingSet[['target']]\n",
    "    meandf=pd.DataFrame(index=np.unique(yTrain['target'].values),columns=trainingSet.columns)\n",
    "    meandf=meandf.drop(columns=['target'])\n",
    "    for i in range(len(meandf)):\n",
    "        meandf0=trainingSet.loc[trainingSet['target'].values == i]\n",
    "        meandf0=meandf0.drop(columns=['target'])\n",
    "        for col in meandf0.columns:\n",
    "            meandf.loc[i,col]=meandf0[col].mean()\n",
    "    return meandf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for expected mean likelihood estimation ...\n",
      "... 'calcMeanLikelihood' test passed successfully :-)\n",
      "likelihood for the mean of petal length for category 1 is estimated as: 4.241463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "meanLiklihoodDf = calcMeanLikelihood(train_set)\n",
    "likelihood_petalLength_class1 = meanLiklihoodDf.iloc[1,2]\n",
    "print ('testing for expected mean likelihood estimation ...')\n",
    "assert int(likelihood_petalLength_class1*10)==42,'wrong mean likelihood estimation for petalLength_class1'\n",
    "print (\"... 'calcMeanLikelihood' test passed successfully :-)\")\n",
    "print ('likelihood for the mean of petal length for category 1 is estimated as: %f' %(likelihood_petalLength_class1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcStdLikelihood(trainingSet):\n",
    "    yTrain = trainingSet[['target']]\n",
    "    std=pd.DataFrame(index=np.unique(yTrain['target'].values),columns=trainingSet.columns)\n",
    "    std=std.drop(columns=['target'])\n",
    "    for i in range(len(std)):\n",
    "        std0=trainingSet.loc[trainingSet['target'].values == i]\n",
    "        std0=std0.drop(columns=['target'])\n",
    "        for col in std0.columns:\n",
    "            std.loc[i,col]=std0[col].std()\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for expected std likelihood estimation ...\n",
      "... 'calcStdLikelihood' test passed successfully :-)\n",
      "likelihood for the std of petal length for category 1 is estimated as: 0.481132\n"
     ]
    }
   ],
   "source": [
    "stdLiklihoodDf = calcStdLikelihood(train_set)\n",
    "likelihood_petalLength_class1 = stdLiklihoodDf.iloc[1,2]\n",
    "print ('testing for expected std likelihood estimation ...')\n",
    "assert int(likelihood_petalLength_class1*10)==4,'wrong std likelihood estimation for petalLength_class1'\n",
    "print (\"... 'calcStdLikelihood' test passed successfully :-)\")\n",
    "print ('likelihood for the std of petal length for category 1 is estimated as: %f' %(likelihood_petalLength_class1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit(trainingSet):\n",
    "    \"\"\"\n",
    "    1. Calculate the class priors of the training set, using the 'calcCategoryPriors' method.\n",
    "    2. Calculate the mean of the training set per feature per class, using the 'calcMeanLikelihood' method.\n",
    "    3. Calculate the std of the training set per feature per class, using the 'stdLiklihoodDf' method.\n",
    "    \"\"\"\n",
    "    arrPriors = calcCategoryPriors(trainingSet)\n",
    "    meanLiklihoodDf = calcMeanLikelihood(trainingSet)\n",
    "    stdLiklihoodDf = calcStdLikelihood(trainingSet)\n",
    "    \n",
    "    return meanLiklihoodDf, stdLiklihoodDf, arrPriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcGaussianProb(xFeatureVal, mean, std):\n",
    "    exponent = np.exp(-((xFeatureVal-mean)**2 / (2 * std**2 )))\n",
    "    return (1 / ((2 * np.pi)**(1/2) * std)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAposteriorProbs(XTest, arrTrainedClassPriors, dfTrainedMean, dfTrainedStd, categories):\n",
    "    numClasses = len(categories)\n",
    "    dfProbPerTestInstPerClass = pd.DataFrame(np.zeros((XTest.shape[0], numClasses)), columns=categories, index=XTest.index)\n",
    "    for category in categories:\n",
    "        classPrior = arrTrainedClassPriors[category]\n",
    "        dfProbPerTestInstPerClass[category]=classPrior\n",
    "        # Check for each row\n",
    "        for nRow in range(XTest.shape[0]):\n",
    "\n",
    "            # Multiply the current given probability by the newly calculated probability for the given event (feature)\n",
    "            for nCol in range(XTest.shape[1]):\n",
    "                xFeatureVal=XTest.iloc[nRow, nCol]\n",
    "                mean=dfTrainedMean.iloc[category,nCol]\n",
    "                std=dfTrainedStd.iloc[category,nCol]\n",
    "                gaussianProb = calcGaussianProb(xFeatureVal, mean, std)\n",
    "                # multiple the prior class probability with the gausian likelihood:\n",
    "                dfProbPerTestInstPerClass.iloc[nRow, category] *= gaussianProb\n",
    "    return dfProbPerTestInstPerClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictClasses(df_probPerTestInstPerClass):\n",
    "    res=pd.Series(index=df_probPerTestInstPerClass.index)\n",
    "    for row in df_probPerTestInstPerClass.index:\n",
    "        res[row]=df_probPerTestInstPerClass.loc[row].idxmax()\n",
    "    print (res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(XTest, arrTrainedClassPriors, dfTrainedMean, dfTrainedStd, categories):\n",
    "    # 1. calculate a posterior probabities:\n",
    "    dfProbPerTestInstPerClass = calcAposteriorProbs(XTest, arrTrainedClassPriors, dfTrainedMean, dfTrainedStd, categories)\n",
    "\n",
    "    # 2. predict classes using the a posterior probabities:\n",
    "    results = predictClasses(dfProbPerTestInstPerClass)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compare how many predictions were correct (compare the y_hat to y)\n",
    "    \"\"\"\n",
    "    accuracy_score = pd.Series(y_true.values == y_pred.values).value_counts() * 100 / y_true.shape[0]\n",
    "    return accuracy_score.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73     1.0\n",
      "18     0.0\n",
      "118    2.0\n",
      "78     1.0\n",
      "76     1.0\n",
      "31     0.0\n",
      "64     1.0\n",
      "141    2.0\n",
      "68     1.0\n",
      "82     1.0\n",
      "110    2.0\n",
      "12     0.0\n",
      "36     0.0\n",
      "9      0.0\n",
      "19     0.0\n",
      "56     1.0\n",
      "104    2.0\n",
      "69     1.0\n",
      "55     1.0\n",
      "132    2.0\n",
      "29     0.0\n",
      "127    2.0\n",
      "26     0.0\n",
      "128    2.0\n",
      "131    2.0\n",
      "145    2.0\n",
      "108    2.0\n",
      "143    2.0\n",
      "45     0.0\n",
      "30     0.0\n",
      "dtype: float64\n",
      "Accuracy Score: 100.0\n"
     ]
    }
   ],
   "source": [
    "# --------------------- \n",
    "## The Following tests the the predict, using the accuracy function\n",
    "# --------------------- \n",
    "meanLiklihoodDf, stdLiklihoodDf, arrPriors=fit(train_set)\n",
    "iris_classes = np.unique(train_set['target'].values)\n",
    "y_hat = predict(X_test, arrPriors, meanLiklihoodDf, stdLiklihoodDf, iris_classes)\n",
    "accuracy_score = evaluate_accuracy(y_test['target'], y_hat)\n",
    "assert accuracy_score == 100, \"accuracy should be 100\"\n",
    "print(\"Accuracy Score: {}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
