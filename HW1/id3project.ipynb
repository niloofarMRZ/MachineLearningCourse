{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sys import argv\n",
    "from math import log, pow\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decisionTree():\n",
    "    # Create a dictionary to hold the tree.  This has to be outside the function so we can access it later.\n",
    "\n",
    "    columns = ['WORKCLASS', 'EDUCATION', 'MARITAL_STATUS', 'OCCUPATION',\n",
    "               'RELATIONSHIP', 'RACE', 'SEX', 'NATIVE_COUNTRY']\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, trainingFile, testFile, model):\n",
    "        self.trainingFile = trainingFile\n",
    "        self.testFile = testFile\n",
    "        self.model = model\n",
    "\n",
    "    # Load data set\n",
    "    def load(self, file_name):\n",
    "        names = [ 'SALARYlEVEL','WORKCLASS', 'EDUCATION', 'MARITAL_STATUS', 'OCCUPATION',\n",
    "                 'RELATIONSHIP', 'RACE', 'SEX', 'NATIVE_COUNTRY']\n",
    "        \n",
    "        X = pd.read_csv(file_name, sep=',', quotechar='\"', header=0, engine='python')\n",
    "        X.columns = names\n",
    "        df = X[[ 'WORKCLASS', 'EDUCATION', 'MARITAL_STATUS', 'OCCUPATION',\n",
    "                 'RELATIONSHIP', 'RACE', 'SEX', 'NATIVE_COUNTRY','SALARYlEVEL']]\n",
    "        data = X.as_matrix()\n",
    "        return data\n",
    "\n",
    "    # Print a decision tree\n",
    "    def print_tree(self, node, depth=0):\n",
    "        if isinstance(node, dict):\n",
    "            print('%s[%s == %s]' % ((depth * ' ', (node['Node']), node['Value'])))\n",
    "            self.print_tree(node['Left'], depth + 1)\n",
    "            self.print_tree(node['Right'], depth + 1)\n",
    "        else:\n",
    "            print('%s[%s]' % ((depth * ' ', node)))\n",
    "\n",
    "    # Calculate accuracy percentage\n",
    "    def accuracy_metric(self, actual, predicted):\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return correct / float(len(actual)) * 100.0\n",
    "\n",
    "    # Calculate entropy\n",
    "    def calcEntropy(self, dataset):\n",
    "        # Compute the counts of each unique value in the column.\n",
    "        num_entries = len(dataset)\n",
    "        label_counts = {}\n",
    "\n",
    "        for feat_vec in dataset:  # the the number of unique elements and their occurance\n",
    "            current_label = feat_vec[-1]\n",
    "            if current_label not in label_counts.keys():\n",
    "                label_counts[current_label] = 0\n",
    "\n",
    "            label_counts[current_label] += 1\n",
    "\n",
    "        # Initialize the entropy to 0.\n",
    "        entropy = 0.0\n",
    "\n",
    "        # Loop through the probabilities, and add each one to the total entropy.\n",
    "        for key in label_counts:\n",
    "            prob = float(label_counts[key]) / num_entries\n",
    "            if prob > 0.0:\n",
    "                entropy += prob * log(prob, 2)  # log base 2\n",
    "\n",
    "        return -entropy\n",
    "\n",
    "    # Split a dataset based on an attribute and an attribute value\n",
    "\n",
    "    def test_split(self, index, value, dataset):\n",
    "\n",
    "        left, right = list(), list()\n",
    "\n",
    "        for row in dataset:\n",
    "            if row[index] == value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return np.asarray(left), np.asarray(right)\n",
    "\n",
    "    # Calculate information gain given a dataset, column to split on, and target.\n",
    "    def calc_information_gain(self, data, index):\n",
    "        # Calculate original entropy.\n",
    "        original_entropy = self.calcEntropy(data)\n",
    "\n",
    "        # Loop through the splits, and calculate the subset entropy.\n",
    "\n",
    "        max_ig = 0.0\n",
    "        ret_value = -1\n",
    "        groups = ()\n",
    "\n",
    "        for value in np.unique(data[:, index]):\n",
    "            test_groups = self.test_split(index, value, data)\n",
    "            to_subtract = 0.0\n",
    "\n",
    "            for subset in test_groups:\n",
    "                if subset.shape[0] > 0:\n",
    "                    prob = (float(subset.shape[0]) / float(data.shape[0]))\n",
    "                    to_subtract += prob * self.calcEntropy(subset)\n",
    "\n",
    "            current_ig = original_entropy - to_subtract\n",
    "\n",
    "            if current_ig > max_ig:\n",
    "                max_ig = current_ig\n",
    "                groups = test_groups\n",
    "                ret_value = value\n",
    "\n",
    "        # Return information gain.\n",
    "        return max_ig, groups, ret_value\n",
    "\n",
    "    # Select the best split point for a dataset\n",
    "    def get_split(self, dataset, columns):\n",
    "        b_node, b_value, b_score, b_groups = 'Nothing', 'Nothing', 0.0, None\n",
    "\n",
    "        # Loop through and compute information gains.\n",
    "        # for index in range(len(columns)):\n",
    "        for index in range(len(columns)):\n",
    "            gain, groups, value = self.calc_information_gain(dataset, index)\n",
    "            if gain > b_score:\n",
    "                b_node, b_value, b_score, b_groups = columns[index], value, gain, groups\n",
    "        return {'Node': b_node, 'Value': b_value, 'Groups': b_groups}\n",
    "\n",
    "    # Create a terminal node value\n",
    "    def to_terminal(self, group):\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "    def count_label(selfself, child):\n",
    "        return [row[-1] for row in child]\n",
    "\n",
    "    # Create child splits for a node or make terminal\n",
    "    def split(self, mytree, columns, max_depth, depth):\n",
    "        left, right = mytree['Groups']\n",
    "        del (mytree['Groups'])\n",
    "        sub_columns = columns[:]\n",
    "        sub_columns.remove(mytree['Node'])\n",
    "        index = columns.index(mytree['Node'])\n",
    "        left = np.delete(left, index, axis=1)\n",
    "        right = np.delete(right, index, axis=1)\n",
    "\n",
    "        if not sub_columns:\n",
    "            mytree['Left'], mytree['Right'] = self.to_terminal(left), self.to_terminal(right)\n",
    "            return\n",
    "\n",
    "        # check for a no split\n",
    "        if not left.tolist() or not right.tolist():\n",
    "            mytree['Left'] = mytree['Right'] = self.to_terminal(left + right)\n",
    "            return\n",
    "\n",
    "        # check for max depth\n",
    "        if depth >= max_depth:\n",
    "            mytree['Left'], mytree['Right'] = self.to_terminal(left), self.to_terminal(right)\n",
    "            return\n",
    "\n",
    "        # process left child\n",
    "        label_list = self.count_label(left)\n",
    "\n",
    "        if label_list.count(label_list[0]) == len(label_list):\n",
    "            mytree['Left'] = self.to_terminal(left)\n",
    "        else:\n",
    "            mytree['Left'] = self.get_split(left, sub_columns)\n",
    "            # if information gain is zero\n",
    "            if mytree['Left']['Node'] == 'Nothing':\n",
    "                mytree['Left'] = self.to_terminal(left)\n",
    "            else:\n",
    "                self.split(mytree['Left'], sub_columns, max_depth, depth + 1)\n",
    "\n",
    "        # process right child\n",
    "        label_list = self.count_label(right)\n",
    "\n",
    "        if label_list.count(label_list[0]) == len(label_list):\n",
    "            mytree['Right'] = self.to_terminal(right)\n",
    "        else:\n",
    "            mytree['Right'] = self.get_split(right, sub_columns)\n",
    "            # if information gain is zero\n",
    "            if mytree['Right']['Node'] == 'Nothing':\n",
    "                mytree['Right'] = self.to_terminal(right)\n",
    "            else:\n",
    "                self.split(mytree['Right'], sub_columns, max_depth, depth + 1)\n",
    "\n",
    "    # Build a decision tree\n",
    "    def build_tree(self, train, max_depth):\n",
    "        root = self.get_split(train, decisionTree.columns)\n",
    "        self.split(root, decisionTree.columns, max_depth, 1)\n",
    "        return root\n",
    "\n",
    "    # Make a prediction with a decision tree\n",
    "    def predict(self, mytree, row):\n",
    "        columns = ['WORKCLASS', 'EDUCATION', 'MARITAL_STATUS', 'OCCUPATION',\n",
    "                   'RELATIONSHIP', 'RACE', 'SEX', 'NATIVE_COUNTRY']\n",
    "        if row[columns.index(mytree['Node'])] == mytree['Value']:\n",
    "            if isinstance(mytree['Left'], dict):\n",
    "                return self.predict(mytree['Left'], row)\n",
    "            else:\n",
    "                return mytree['Left']\n",
    "        else:\n",
    "            if isinstance(mytree['Right'], dict):\n",
    "                return self.predict(mytree['Right'], row)\n",
    "            else:\n",
    "                return mytree['Right']\n",
    "\n",
    "    def is_tree(self, obj):\n",
    "        return (type(obj).__name__ == 'dict')\n",
    "\n",
    "    def testing_major(self, major, data_test):\n",
    "        error = 0.0\n",
    "        for i in range(len(data_test)):\n",
    "            if major != data_test[i]:\n",
    "                error += 1\n",
    "                # print 'major %d' %error\n",
    "        return float(error)\n",
    "\n",
    "    def prune(self, tree, test_data):\n",
    "        # if have no test data collapse the tree\n",
    "        if test_data.shape[0] == 0:\n",
    "            return '>50K'\n",
    "\n",
    "        left_set = []\n",
    "        right_set = []\n",
    "        # if the branches are not trees try to prune them\n",
    "        if (self.is_tree(tree['Right']) or self.is_tree(tree['Left'])):\n",
    "            left_set, right_set = self.test_split(decisionTree.columns.index(tree['Node']), tree['Value'], test_data)\n",
    "\n",
    "        if self.is_tree(tree['Left']):\n",
    "            tree['Left'] = self.prune(tree['Left'], left_set)\n",
    "\n",
    "        if self.is_tree(tree['Right']):\n",
    "            tree['Right'] = self.prune(tree['Right'], right_set)\n",
    "\n",
    "        # if they are now both leafs, see if can merge them\n",
    "        if not self.is_tree(tree['Left']) and not self.is_tree(tree['Right']):\n",
    "            left_set, right_set = self.test_split(decisionTree.columns.index(tree['Node']), tree['Value'], test_data)\n",
    "\n",
    "            if left_set.shape[0] == 0:\n",
    "                left_error_sum = 0\n",
    "            else:\n",
    "                left_error_sum = self.testing_major(tree['Left'], left_set[:, -1])\n",
    "\n",
    "            if right_set.shape[0] == 0:\n",
    "                right_error_sum = 0\n",
    "            else:\n",
    "                right_error_sum = self.testing_major(tree['Right'], right_set[:, -1])\n",
    "\n",
    "            error_no_merge = pow(left_error_sum, 2) + pow(right_error_sum, 2)\n",
    "            tree_mean = self.to_terminal(test_data)\n",
    "            error_merge = pow(self.testing_major(tree_mean, test_data[:, -1]), 2)\n",
    "\n",
    "            if error_merge < error_no_merge:\n",
    "                # print \"merging\"\n",
    "                return tree_mean\n",
    "            else:\n",
    "                return tree\n",
    "        else:\n",
    "            return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vanillaTree(decisionTree):\n",
    "    def __init__(self, trainingFile, testFile, model, trainingPercent):\n",
    "        decisionTree.__init__(self, trainingFile, testFile, model)\n",
    "        self.trainingPercent = trainingPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pruneTree(decisionTree):\n",
    "    def __init__(self, trainingFile, testFile, model, trainingPercent, validationPercent):\n",
    "        decisionTree.__init__(self, trainingFile, testFile, model)\n",
    "        self.trainingPercent = trainingPercent\n",
    "        self.validationPercent = validationPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the tree.  This has to be outside the function so we can access it later.\n",
    "tree = {}\n",
    "# This list will let us number the nodes.  It has to be a list so we can access it inside the function.\n",
    "nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_file:adult.data\n",
      "test_file:adult.test\n",
      "model:vanilla\n",
      "training_percent:2\n",
      "{'Node': 'RELATIONSHIP', 'Value': ' Husband', 'Left': {'Node': 'EDUCATION', 'Value': ' 11th', 'Left': ' <=50K', 'Right': {'Node': 'WORKCLASS', 'Value': 'Local-gov', 'Left': ' >50K', 'Right': {'Node': 'RACE', 'Value': ' Asian-Pac-Islander', 'Left': ' >50K', 'Right': {'Node': 'OCCUPATION', 'Value': ' Exec-managerial', 'Left': ' >50K', 'Right': {'Node': 'NATIVE_COUNTRY', 'Value': ' United-States', 'Left': ' <=50K', 'Right': ' <=50K'}}}}}, 'Right': {'Node': 'WORKCLASS', 'Value': 'Federal-gov', 'Left': {'Node': 'EDUCATION', 'Value': ' Bachelors', 'Left': ' >50K', 'Right': ' <=50K'}, 'Right': {'Node': 'SEX', 'Value': ' Female', 'Left': {'Node': 'RACE', 'Value': ' White', 'Left': {'Node': 'OCCUPATION', 'Value': ' Adm-clerical', 'Left': ' <=50K', 'Right': {'Node': 'EDUCATION', 'Value': ' Prof-school', 'Left': ' >50K', 'Right': {'Node': 'MARITAL_STATUS', 'Value': ' Married-spouse-absent', 'Left': ' <=50K', 'Right': {'Node': 'NATIVE_COUNTRY', 'Value': ' England', 'Left': ' <=50K', 'Right': ' <=50K'}}}}, 'Right': ' <=50K'}, 'Right': ' <=50K'}}}\n",
      "Training set accuracy: 0.8744\n",
      "Test set accuracy: 0.7794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "if __name__ == '__main__':\n",
    "    training_file= input('training_file:')\n",
    "    \n",
    "    test_file= input('test_file:')\n",
    "    model= input('model:')\n",
    "    training_percent= input('training_percent:')\n",
    "    \"\"\"\"\n",
    "    training_file = argv[1]\n",
    "    test_file = argv[2]\n",
    "    model = argv[3]\n",
    "    training_percent = argv[4]\n",
    "    \"\"\"\n",
    "\n",
    "    # Implement a binary decision tree with no pruning using the ID3 algorithm\n",
    "    if model == \"vanilla\":\n",
    "        vani_tree = vanillaTree(training_file, test_file, model, training_percent)\n",
    "\n",
    "        train = vani_tree.load(training_file)\n",
    "        subtrain = copy.deepcopy(train)\n",
    "        subtrain = train[0:int(len(train) * int(training_percent) / 100), :]\n",
    "        shuffle(subtrain)\n",
    "        max_depth = float(\"inf\")\n",
    "\n",
    "        tree = vani_tree.build_tree(subtrain, max_depth)\n",
    "\n",
    "        # vani_tree.print_tree(tree)\n",
    "        print(tree)\n",
    "\n",
    "        predictions_train = list()\n",
    "        for row in subtrain:\n",
    "            pd_train = vani_tree.predict(tree, row)\n",
    "            predictions_train.append(pd_train)\n",
    "\n",
    "        accuracy = vani_tree.accuracy_metric(subtrain[:, -1], predictions_train) / 100\n",
    "        print(\"Training set accuracy: %.4f\" % accuracy)\n",
    "\n",
    "        test = vani_tree.load(test_file)\n",
    "        predictions_test = list()\n",
    "        for row in test:\n",
    "            pd_test = vani_tree.predict(tree, row)\n",
    "            predictions_test.append(pd_test)\n",
    "\n",
    "        accuracy = vani_tree.accuracy_metric(test[:, -1], predictions_test) / 100\n",
    "        print(\"Test set accuracy: %.4f\" % accuracy)\n",
    "\n",
    "    # Implement a binary decision tree with a given maximum depth\n",
    "    \n",
    "    elif model == \"prune\":\n",
    "        validation_percent= input('validation_percent:')\n",
    "        #validation_percent = argv[5]\n",
    "\n",
    "        # Create pruneTree object\n",
    "        prune_tree = pruneTree(training_file, test_file, model, training_percent, validation_percent)\n",
    "\n",
    "        # Read training data from file\n",
    "        data_set = prune_tree.load(training_file)\n",
    "        train_set = copy.deepcopy(data_set)\n",
    "        validation_set = copy.deepcopy(data_set)\n",
    "\n",
    "        max_depth = float(\"inf\")\n",
    "\n",
    "        # Prepare training data set\n",
    "        train_set = data_set[0:int(len(data_set) * int(training_percent) / 100), :]\n",
    "\n",
    "        # Prepare validation data set\n",
    "        validation_set = validation_set[int(len(validation_set) * (100 - int(validation_percent)) / 100):, :]\n",
    "\n",
    "        # Build decision tree of max_depth\n",
    "        tree = prune_tree.build_tree(train_set, max_depth)\n",
    "\n",
    "        # Prepare test data set\n",
    "        test_set = prune_tree.load(test_file)\n",
    "\n",
    "        # Build decision tree with post-pruning using reduced error pruning\n",
    "        post_prune_tree = prune_tree.prune(tree, validation_set)\n",
    "\n",
    "        predictions_train = list()\n",
    "        for row in train_set:\n",
    "            pd_train = prune_tree.predict(post_prune_tree, row)\n",
    "            predictions_train.append(pd_train)\n",
    "\n",
    "        accuracy = prune_tree.accuracy_metric(train_set[:, -1], predictions_train) / 100\n",
    "        print(\"Training set accuracy: %.4f\" % accuracy)\n",
    "\n",
    "        predictions_test = list()\n",
    "        for row in test_set:\n",
    "            pd_test = prune_tree.predict(post_prune_tree, row)\n",
    "            predictions_test.append(pd_test)\n",
    "\n",
    "        accuracy = prune_tree.accuracy_metric(test_set[:, -1], predictions_test) / 100\n",
    "        print(\"Test set accuracy: %.4f\" % accuracy)\n",
    "\n",
    "        #prune_tree.print_tree(tree)\n",
    "\n",
    "    else:\n",
    "        print(\"wrong inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
